

\title[Systems Engineering]{ System Model} 



\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM and System Engineering }

 \colorbox{green}{ \textcolor{white}{ System MODEL } }

Matlab, LabView, Simulink etc  for Model Based SE

\end{block}
\end{frame}


\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM : Input Embeddings }

 The input text is tokenized into smaller units, such as words or subwords, and each token is embedded into a continuous vector representation. This embedding step captures the semantic and syntactic information of the input.
 
\end{block}
\end{frame}


\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM : Positional Encoding }

Positional encoding is added to the input embeddings to provide information about the positions of the tokens because transformers do not naturally encode the order of the tokens. This enables the model to process the tokens while taking their sequential order into account.
 
\end{block}
\end{frame}


\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM : Encoder }

Based on a neural network technique, the encoder analyses the input text and creates a number of hidden states that protect the context and meaning of text data. Multiple encoder layers make up the core of the transformer architecture. Self-attention mechanism and feed-forward neural network are the two fundamental sub-components of each encoder layer.
 
\end{block}
\end{frame}


\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM : Encoder}

Self-Attention Mechanism: Self-attention enables the model to weigh the importance of different tokens in the input sequence by computing attention scores. It allows the model to consider the dependencies and relationships between different tokens in a context-aware manner.
 
\end{block}
\end{frame}

\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM : Encoder }

 Feed-Forward Neural Network: After the self-attention step, a feed-forward neural network is applied to each token independently. This network includes fully connected layers with non-linear activation functions, allowing the model to capture complex interactions between tokens.
 
\end{block}
\end{frame}


\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM : Decoder Layers }

  In some transformer-based models, a decoder component is included in addition to the encoder. The decoder layers enable autoregressive generation, where the model can generate sequential outputs by attending to the previously generated tokens.
 
\end{block}
\end{frame}


\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM : Multi-Head Attention}

  Transformers often employ multi-head attention, where self-attention is performed simultaneously with different learned attention weights. This allows the model to capture different types of relationships and attend to various parts of the input sequence simultaneously.

   \colorbox{green}{ \textcolor{white}{ Input Sequence } }
   
\end{block}
\end{frame}



\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM :  Layer Normalization }

 Layer normalization is applied after each sub-component or layer in the transformer architecture. It helps stabilize the learning process and improves the model’s ability to generalize across different inputs.

  \colorbox{green}{ \textcolor{white}{ Multi inputs from team } }
  
\end{block}
\end{frame}




\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM : Output Layers }

The output layers of the transformer model can vary depending on the specific task. For example, in language modeling, a linear projection followed by softmax activation is commonly used to generate the probability distribution over the next token.

 \colorbox{green}{ \textcolor{white}{ How to design Output } }
 
\end{block}
\end{frame}




\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{Examples of LLM }

 \colorbox{green}{ \textcolor{white}{ ???????? } }
 
\end{block}
\end{frame}




\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM Use : Code Generation }

 One of the craziest use cases of this service is that it can generate quite an accurate code for a specific task that is described by the user to the model.

 \colorbox{green}{ \textcolor{white}{  Low Code and more Focus on Work} }
 
\end{block}
\end{frame}


\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM Use :  Debugging and Documentation of Code}
 
 If you are struggling with some piece of code regarding how to debug it then ChatGPT is your savior because it can tell you the line of code which are creating issues along with the remedy to correct the same. Also now you don’t have to spend hours writing the documentation of your project you can ask ChatGPT to do this for you.
 
\colorbox{green}{ \textcolor{white}{ Documentation of Issues in Code } }
 
\end{block}
\end{frame}


\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM Use : Question Answering  }

 As you must have seen that when AI-powered personal assistants were released people used to ask crazy questions to them well you can do that here as well along with the genuine questions

  \colorbox{green}{ \textcolor{white}{ Review Requirements  } }
  
\end{block}
\end{frame}

\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM Use : Language Transfer }

 It can convert a piece of text from one language to another as it supports more than 50 native languages. It can also help you correct the grammatical mistakes in your content.


  \colorbox{green}{ \textcolor{white}{ Multinational Team in a Project } }
  
\end{block}
\end{frame}

\newpage
\begin{frame}
\frametitle{ System Model }
\begin{block}{LLM and NVIDIA }

NVIDIA offers multiple services for the easy handling of LLMs and which can vary from domain-specific LLMs that are NVIDIA BioNemo to NVIDIA Nemo framework for building LLMs.



\colorbox{green}{ \textcolor{white}{ Build your OWN Models  } }


 
\end{block}
\end{frame}

